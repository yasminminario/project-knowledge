{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849fdac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# EXEMPLO PRÁTICO PARA GOOGLE COLAB\n",
    "# Execute este código célula por célula\n",
    "\n",
    "# 1. INSTALAR DEPENDÊNCIAS\n",
    "!pip install pandas colorama difflib\n",
    "\n",
    "# 2. IMPORTAR E CONFIGURAR\n",
    "import pandas as pd\n",
    "import io\n",
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "from difflib import SequenceMatcher\n",
    "import difflib\n",
    "\n",
    "class ContentValidator:\n",
    "    def __init__(self):\n",
    "        self.original_content = {}\n",
    "        self.generated_content = \"\"\n",
    "        self.missing_content = []\n",
    "        self.added_content = []\n",
    "        self.coverage_report = {}\n",
    "\n",
    "    def load_original_data(self, csv_path: str):\n",
    "        \"\"\"Carrega os dados originais do CSV\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filtra apenas as linhas com respostas válidas\n",
    "        valid_rows = df[\n",
    "            (df['answer'].notna()) &\n",
    "            (df['answer'] != '')\n",
    "        ]\n",
    "\n",
    "        for idx, row in valid_rows.iterrows():\n",
    "            key = f\"item_{idx}\"\n",
    "            self.original_content[key] = {\n",
    "                'answer': row['answer']\n",
    "            }\n",
    "\n",
    "    def load_generated_content(self, generated_text: str):\n",
    "        \"\"\"Carrega o conteúdo gerado\"\"\"\n",
    "        self.generated_content = generated_text\n",
    "\n",
    "    def normalize_text(self, text: str) -> str:\n",
    "        \"\"\"Normaliza texto para comparação mais flexível\"\"\"\n",
    "        # Remove acentos básicos\n",
    "        replacements = {\n",
    "            'á': 'a', 'à': 'a', 'ã': 'a', 'â': 'a', 'ä': 'a',\n",
    "            'é': 'e', 'è': 'e', 'ê': 'e', 'ë': 'e',\n",
    "            'í': 'i', 'ì': 'i', 'î': 'i', 'ï': 'i',\n",
    "            'ó': 'o', 'ò': 'o', 'õ': 'o', 'ô': 'o', 'ö': 'o',\n",
    "            'ú': 'u', 'ù': 'u', 'û': 'u', 'ü': 'u',\n",
    "            'ç': 'c', 'ñ': 'n'\n",
    "        }\n",
    "\n",
    "        text = text.lower()\n",
    "        for old, new in replacements.items():\n",
    "            text = text.replace(old, new)\n",
    "\n",
    "        # Remove pontuação e normaliza espaços\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def extract_key_concepts(self, text: str) -> List[str]:\n",
    "        \"\"\"Extrai conceitos-chave do texto (palavras e frases importantes)\"\"\"\n",
    "        normalized = self.normalize_text(text)\n",
    "\n",
    "        # Palavras importantes (substantivos, verbos, adjetivos)\n",
    "        words = normalized.split()\n",
    "\n",
    "        # Filtrar palavras muito comuns\n",
    "        stopwords = {\n",
    "            'a', 'e', 'o', 'de', 'da', 'do', 'em', 'para', 'com', 'por', 'que', 'se', 'na', 'no',\n",
    "            'um', 'uma', 'os', 'as', 'dos', 'das', 'nos', 'nas', 'ao', 'aos', 'pela', 'pelo',\n",
    "            'mas', 'ou', 'quando', 'onde', 'como', 'muito', 'mais', 'menos', 'ate', 'seu', 'sua',\n",
    "            'seus', 'suas', 'meu', 'minha', 'meus', 'minhas', 'era', 'foi', 'ser', 'ter', 'estar',\n",
    "            'foi', 'tinha', 'tem', 'tinha', 'eram', 'sendo', 'sido', 'ja', 'sempre', 'nunca',\n",
    "            'tambem', 'ainda', 'depois', 'antes', 'entao', 'isso', 'essa', 'este', 'esta',\n",
    "            'aquele', 'aquela', 'dele', 'dela', 'deles', 'delas', 'me', 'te', 'lhe', 'nos', 'vos'\n",
    "        }\n",
    "\n",
    "        # Palavras importantes (pelo menos 3 caracteres e não stopwords)\n",
    "        key_words = [word for word in words if len(word) >= 3 and word not in stopwords]\n",
    "\n",
    "        # Frases importantes (sequências de 2-4 palavras)\n",
    "        key_phrases = []\n",
    "        for i in range(len(key_words) - 1):\n",
    "            phrase = ' '.join(key_words[i:i+2])\n",
    "            if len(phrase) > 8:  # Frases com mais de 8 caracteres\n",
    "                key_phrases.append(phrase)\n",
    "\n",
    "        # Combinar palavras e frases\n",
    "        return key_words + key_phrases\n",
    "\n",
    "    def calculate_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"Calcula similaridade entre dois textos usando diferentes métricas\"\"\"\n",
    "        norm1 = self.normalize_text(text1)\n",
    "        norm2 = self.normalize_text(text2)\n",
    "\n",
    "        # Similaridade básica usando SequenceMatcher\n",
    "        basic_similarity = SequenceMatcher(None, norm1, norm2).ratio()\n",
    "\n",
    "        # Similaridade baseada em conceitos-chave\n",
    "        concepts1 = set(self.extract_key_concepts(text1))\n",
    "        concepts2 = set(self.extract_key_concepts(text2))\n",
    "\n",
    "        if not concepts1 or not concepts2:\n",
    "            concept_similarity = 0.0\n",
    "        else:\n",
    "            intersection = len(concepts1 & concepts2)\n",
    "            union = len(concepts1 | concepts2)\n",
    "            concept_similarity = intersection / union if union > 0 else 0.0\n",
    "\n",
    "        # Peso maior para similaridade de conceitos\n",
    "        final_similarity = (basic_similarity * 0.3) + (concept_similarity * 0.7)\n",
    "\n",
    "        return final_similarity\n",
    "\n",
    "    def check_content_presence(self, original_answer: str, generated_text: str) -> Dict:\n",
    "        \"\"\"Verifica se o conteúdo original está presente no texto gerado\"\"\"\n",
    "        # Extrai conceitos-chave do texto original\n",
    "        original_concepts = self.extract_key_concepts(original_answer)\n",
    "\n",
    "        # Normaliza o texto gerado\n",
    "        normalized_generated = self.normalize_text(generated_text)\n",
    "\n",
    "        # Verifica quantos conceitos estão presentes\n",
    "        present_concepts = []\n",
    "        missing_concepts = []\n",
    "\n",
    "        for concept in original_concepts:\n",
    "            if concept in normalized_generated:\n",
    "                present_concepts.append(concept)\n",
    "            else:\n",
    "                # Verifica similaridade parcial\n",
    "                found_similar = False\n",
    "                for word in normalized_generated.split():\n",
    "                    if self.calculate_similarity(concept, word) > 0.8:\n",
    "                        present_concepts.append(concept)\n",
    "                        found_similar = True\n",
    "                        break\n",
    "\n",
    "                if not found_similar:\n",
    "                    missing_concepts.append(concept)\n",
    "\n",
    "        total_concepts = len(original_concepts)\n",
    "        present_count = len(present_concepts)\n",
    "\n",
    "        coverage_percent = (present_count / total_concepts) * 100 if total_concepts > 0 else 0\n",
    "\n",
    "        return {\n",
    "            'total_concepts': total_concepts,\n",
    "            'present_concepts': present_count,\n",
    "            'coverage_percent': coverage_percent,\n",
    "            'missing_concepts': missing_concepts[:5],  # Apenas os primeiros 5\n",
    "            'similarity_score': self.calculate_similarity(original_answer, generated_text) * 100\n",
    "        }\n",
    "\n",
    "    def compare_character_count(self) -> Dict:\n",
    "        \"\"\"Compara a quantidade de caracteres entre original e gerado\"\"\"\n",
    "        # Contar caracteres do conteúdo original\n",
    "        original_chars = sum(len(item['answer']) for item in self.original_content.values())\n",
    "        generated_chars = len(self.generated_content)\n",
    "\n",
    "        # Calcular diferença percentual\n",
    "        if original_chars > 0:\n",
    "            expansion_ratio = generated_chars / original_chars\n",
    "            difference_percent = ((generated_chars - original_chars) / original_chars) * 100\n",
    "        else:\n",
    "            expansion_ratio = 0\n",
    "            difference_percent = 0\n",
    "\n",
    "        return {\n",
    "            'original_chars': original_chars,\n",
    "            'generated_chars': generated_chars,\n",
    "            'expansion_ratio': expansion_ratio,\n",
    "            'difference_percent': difference_percent,\n",
    "            'status': self._get_expansion_status(expansion_ratio)\n",
    "        }\n",
    "\n",
    "    def _get_expansion_status(self, ratio: float) -> str:\n",
    "        \"\"\"Determina o status baseado na razão de expansão\"\"\"\n",
    "        if ratio < 0.5:\n",
    "            return \"❌ MUITO COMPRIMIDO\"\n",
    "        elif ratio < 0.8:\n",
    "            return \"⚠️ COMPRIMIDO\"\n",
    "        elif ratio < 1.2:\n",
    "            return \"✅ SIMILAR\"\n",
    "        elif ratio < 2.0:\n",
    "            return \"✅ EXPANDIDO\"\n",
    "        elif ratio < 3.0:\n",
    "            return \"⚠️ MUITO EXPANDIDO\"\n",
    "        else:\n",
    "            return \"❌ EXTREMAMENTE EXPANDIDO\"\n",
    "\n",
    "    def check_content_coverage(self) -> Dict:\n",
    "        \"\"\"Verifica cobertura do conteúdo com lógica melhorada\"\"\"\n",
    "        coverage_report = {\n",
    "            'total_original_items': len(self.original_content),\n",
    "            'covered_items': 0,\n",
    "            'missing_items': [],\n",
    "            'coverage_percentage': 0,\n",
    "            'details': [],\n",
    "            'character_analysis': self.compare_character_count()\n",
    "        }\n",
    "\n",
    "        for key, item in self.original_content.items():\n",
    "            presence_analysis = self.check_content_presence(item['answer'], self.generated_content)\n",
    "\n",
    "            item_report = {\n",
    "                'key': key,\n",
    "                'answer': item['answer'],\n",
    "                'coverage_percent': presence_analysis['coverage_percent'],\n",
    "                'similarity_score': presence_analysis['similarity_score'],\n",
    "                'present_concepts': presence_analysis['present_concepts'],\n",
    "                'total_concepts': presence_analysis['total_concepts'],\n",
    "                'missing_concepts': presence_analysis['missing_concepts']\n",
    "            }\n",
    "\n",
    "            coverage_report['details'].append(item_report)\n",
    "\n",
    "            # Considera coberto se tem boa cobertura de conceitos OU alta similaridade\n",
    "            if presence_analysis['coverage_percent'] > 40 or presence_analysis['similarity_score'] > 30:\n",
    "                coverage_report['covered_items'] += 1\n",
    "            else:\n",
    "                coverage_report['missing_items'].append(item_report)\n",
    "\n",
    "        coverage_report['coverage_percentage'] = (\n",
    "            coverage_report['covered_items'] / coverage_report['total_original_items']\n",
    "        ) * 100\n",
    "\n",
    "        return coverage_report\n",
    "\n",
    "    def generate_diff_report(self) -> str:\n",
    "        \"\"\"Gera relatório melhorado no estilo diff do GitHub\"\"\"\n",
    "        coverage = self.check_content_coverage()\n",
    "        char_analysis = coverage['character_analysis']\n",
    "\n",
    "        report = []\n",
    "        report.append(\"# 📊 RELATÓRIO DE VALIDAÇÃO DE CONTEÚDO - VERSÃO MELHORADA\")\n",
    "        report.append(\"=\" * 70)\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Resumo geral\n",
    "        report.append(\"## 📈 RESUMO GERAL\")\n",
    "        report.append(f\"- **Total de itens originais:** {coverage['total_original_items']}\")\n",
    "        report.append(f\"- **Itens cobertos:** {coverage['covered_items']}\")\n",
    "        report.append(f\"- **Cobertura geral:** {coverage['coverage_percentage']:.1f}%\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Análise de caracteres\n",
    "        report.append(\"## 📏 ANÁLISE DE CARACTERES\")\n",
    "        report.append(f\"- **Caracteres originais:** {char_analysis['original_chars']:,}\")\n",
    "        report.append(f\"- **Caracteres gerados:** {char_analysis['generated_chars']:,}\")\n",
    "        report.append(f\"- **Razão de expansão:** {char_analysis['expansion_ratio']:.2f}x\")\n",
    "        report.append(f\"- **Diferença percentual:** {char_analysis['difference_percent']:+.1f}%\")\n",
    "        report.append(f\"- **Status:** {char_analysis['status']}\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Status da cobertura\n",
    "        if coverage['coverage_percentage'] >= 80:\n",
    "            status = \"✅ EXCELENTE\"\n",
    "        elif coverage['coverage_percentage'] >= 60:\n",
    "            status = \"✅ BOM\"\n",
    "        elif coverage['coverage_percentage'] >= 40:\n",
    "            status = \"⚠️ REGULAR\"\n",
    "        else:\n",
    "            status = \"❌ INSUFICIENTE\"\n",
    "\n",
    "        report.append(f\"**Status Geral:** {status}\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Itens bem cobertos\n",
    "        well_covered = [item for item in coverage['details'] if item['coverage_percent'] >= 60 or item['similarity_score'] >= 40]\n",
    "        if well_covered:\n",
    "            report.append(\"## ✅ CONTEÚDO BEM COBERTO\")\n",
    "            report.append(\"\")\n",
    "            for item in well_covered:\n",
    "                report.append(f\"### + {item['key']}\")\n",
    "                report.append(f\"**Cobertura de conceitos:** {item['coverage_percent']:.1f}% ({item['present_concepts']}/{item['total_concepts']})\")\n",
    "                report.append(f\"**Similaridade:** {item['similarity_score']:.1f}%\")\n",
    "                report.append(\"```diff\")\n",
    "                report.append(f\"+ ✅ Conteúdo bem integrado no capítulo\")\n",
    "                report.append(\"```\")\n",
    "                report.append(\"\")\n",
    "\n",
    "        # Itens com cobertura parcial\n",
    "        partial_covered = [item for item in coverage['details']\n",
    "                          if (20 <= item['coverage_percent'] < 60) and item['similarity_score'] < 40]\n",
    "        if partial_covered:\n",
    "            report.append(\"## ⚠️ CONTEÚDO PARCIALMENTE COBERTO\")\n",
    "            report.append(\"\")\n",
    "            for item in partial_covered:\n",
    "                report.append(f\"### ~ {item['key']}\")\n",
    "                report.append(f\"**Cobertura de conceitos:** {item['coverage_percent']:.1f}% ({item['present_concepts']}/{item['total_concepts']})\")\n",
    "                report.append(f\"**Similaridade:** {item['similarity_score']:.1f}%\")\n",
    "                report.append(\"```diff\")\n",
    "                report.append(f\"~ ⚠️ Parte do conteúdo pode estar ausente ou muito reformulado\")\n",
    "                if item['missing_concepts']:\n",
    "                    report.append(\"- Conceitos possivelmente ausentes:\")\n",
    "                    for concept in item['missing_concepts']:\n",
    "                        report.append(f\"- {concept}\")\n",
    "                report.append(\"```\")\n",
    "                report.append(\"\")\n",
    "\n",
    "        # Itens com baixa cobertura\n",
    "        low_covered = [item for item in coverage['details']\n",
    "                      if item['coverage_percent'] < 20 and item['similarity_score'] < 30]\n",
    "        if low_covered:\n",
    "            report.append(\"## ❌ CONTEÚDO COM BAIXA COBERTURA\")\n",
    "            report.append(\"\")\n",
    "            for item in low_covered:\n",
    "                report.append(f\"### - {item['key']}\")\n",
    "                report.append(f\"**Cobertura de conceitos:** {item['coverage_percent']:.1f}% ({item['present_concepts']}/{item['total_concepts']})\")\n",
    "                report.append(f\"**Similaridade:** {item['similarity_score']:.1f}%\")\n",
    "                report.append(\"```diff\")\n",
    "                report.append(f\"- ❌ Conteúdo significativamente ausente\")\n",
    "                report.append(\"- Resposta original:\")\n",
    "                answer_preview = item['answer'][:300] + \"...\" if len(item['answer']) > 300 else item['answer']\n",
    "                report.append(f\"- {answer_preview}\")\n",
    "                report.append(\"```\")\n",
    "                report.append(\"\")\n",
    "\n",
    "        # Recomendações\n",
    "        report.append(\"## 🔍 RECOMENDAÇÕES\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        if coverage['coverage_percentage'] < 60:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"- ⚠️ ATENÇÃO: Cobertura abaixo do ideal\")\n",
    "            report.append(\"+ Revisar itens com baixa cobertura\")\n",
    "            report.append(\"+ Verificar se informações importantes foram omitidas\")\n",
    "            report.append(\"+ Considerar incluir mais detalhes dos itens ausentes\")\n",
    "            report.append(\"```\")\n",
    "        else:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"+ ✅ Cobertura satisfatória\")\n",
    "            report.append(\"+ Conteúdo bem integrado e reformulado\")\n",
    "            report.append(\"+ Capítulo pronto para revisão final\")\n",
    "            report.append(\"```\")\n",
    "\n",
    "        # Análise da expansão\n",
    "        report.append(\"\")\n",
    "        report.append(\"## 📊 ANÁLISE DE EXPANSÃO\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        if char_analysis['expansion_ratio'] < 0.8:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"- ⚠️ Conteúdo pode estar muito comprimido\")\n",
    "            report.append(\"+ Considerar adicionar mais detalhes e contexto\")\n",
    "            report.append(\"```\")\n",
    "        elif char_analysis['expansion_ratio'] > 2.5:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"- ⚠️ Conteúdo pode estar muito expandido\")\n",
    "            report.append(\"+ Verificar se há informações desnecessárias\")\n",
    "            report.append(\"```\")\n",
    "        else:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"+ ✅ Expansão adequada para um capítulo narrativo\")\n",
    "            report.append(\"```\")\n",
    "\n",
    "        report.append(\"\")\n",
    "        report.append(\"---\")\n",
    "        report.append(\"*Relatório gerado automaticamente pelo ContentValidator v2.0*\")\n",
    "        report.append(\"*Lógica melhorada para análise de conteúdo reformulado*\")\n",
    "\n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "    def run_validation(self, csv_path: str, generated_text: str) -> str:\n",
    "        \"\"\"Executa validação completa\"\"\"\n",
    "        print(\"🔄 Carregando dados originais...\")\n",
    "        self.load_original_data(csv_path)\n",
    "\n",
    "        print(\"🔄 Carregando conteúdo gerado...\")\n",
    "        self.load_generated_content(generated_text)\n",
    "\n",
    "        print(\"🔄 Analisando cobertura com lógica melhorada...\")\n",
    "\n",
    "        print(\"🔄 Gerando relatório...\")\n",
    "        report = self.generate_diff_report()\n",
    "\n",
    "        return report\n",
    "\n",
    "# 3. PREPARAR DADOS DE EXEMPLO\n",
    "csv_data = \"/caminho_para_csv_com_answers\"\n",
    "\n",
    "# 4. DEFINIR CONTEÚDO GERADO (cole seu capítulo aqui)\n",
    "generated_text = \"\"\"\n",
    "*CONTEÚDO GERADO*\n",
    "\"\"\"\n",
    "\n",
    "# 5. EXECUTAR VALIDAÇÃO\n",
    "validator = ContentValidator()\n",
    "\n",
    "# Executar validação\n",
    "print(\"🚀 Iniciando validação com lógica melhorada...\")\n",
    "report = validator.run_validation(csv_data, generated_text)\n",
    "\n",
    "# 6. EXIBIR RESULTADO\n",
    "display(Markdown(report))\n",
    "\n",
    "# 7. FUNÇÃO PARA ANÁLISE DETALHADA\n",
    "def detailed_analysis(validator):\n",
    "    \"\"\"Análise detalhada item por item\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ANÁLISE DETALHADA ITEM POR ITEM\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    coverage = validator.check_content_coverage()\n",
    "\n",
    "    for i, item in enumerate(coverage['details'], 1):\n",
    "        print(f\"\\n{i}. {item['key']}\")\n",
    "        print(f\"   Cobertura de conceitos: {item['coverage_percent']:.1f}%\")\n",
    "        print(f\"   Similaridade geral: {item['similarity_score']:.1f}%\")\n",
    "        print(f\"   Conceitos presentes: {item['present_concepts']}/{item['total_concepts']}\")\n",
    "\n",
    "        if item['coverage_percent'] >= 60 or item['similarity_score'] >= 40:\n",
    "            print(\"   Status: ✅ BEM COBERTO\")\n",
    "        elif item['coverage_percent'] >= 20 or item['similarity_score'] >= 20:\n",
    "            print(\"   Status: ⚠️ PARCIALMENTE COBERTO\")\n",
    "        else:\n",
    "            print(\"   Status: ❌ BAIXA COBERTURA\")\n",
    "\n",
    "        if item['missing_concepts']:\n",
    "            print(\"   Conceitos ausentes:\")\n",
    "            for concept in item['missing_concepts']:\n",
    "                print(f\"   - {concept}\")\n",
    "\n",
    "# Executar análise detalhada\n",
    "detailed_analysis(validator)\n",
    "\n",
    "# 8. FUNÇÃO PARA RELATÓRIO DE CONCEITOS\n",
    "def concept_analysis_report(validator):\n",
    "    \"\"\"Relatório focado em conceitos-chave\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RELATÓRIO DE CONCEITOS-CHAVE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for key, item in validator.original_content.items():\n",
    "        print(f\"\\n📝 {key}:\")\n",
    "        print(f\"Texto original: {item['answer'][:200]}...\")\n",
    "\n",
    "        concepts = validator.extract_key_concepts(item['answer'])\n",
    "        print(f\"Conceitos extraídos: {concepts[:10]}\")  # Primeiros 10\n",
    "\n",
    "        presence = validator.check_content_presence(item['answer'], validator.generated_content)\n",
    "        print(f\"Cobertura: {presence['coverage_percent']:.1f}%\")\n",
    "        print(f\"Similaridade: {presence['similarity_score']:.1f}%\")\n",
    "\n",
    "# Executar análise de conceitos\n",
    "concept_analysis_report(validator)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
