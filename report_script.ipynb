{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849fdac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# EXEMPLO PR√ÅTICO PARA GOOGLE COLAB\n",
    "# Execute este c√≥digo c√©lula por c√©lula\n",
    "\n",
    "# 1. INSTALAR DEPEND√äNCIAS\n",
    "!pip install pandas colorama difflib\n",
    "\n",
    "# 2. IMPORTAR E CONFIGURAR\n",
    "import pandas as pd\n",
    "import io\n",
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "from difflib import SequenceMatcher\n",
    "import difflib\n",
    "\n",
    "class ContentValidator:\n",
    "    def __init__(self):\n",
    "        self.original_content = {}\n",
    "        self.generated_content = \"\"\n",
    "        self.missing_content = []\n",
    "        self.added_content = []\n",
    "        self.coverage_report = {}\n",
    "\n",
    "    def load_original_data(self, csv_path: str):\n",
    "        \"\"\"Carrega os dados originais do CSV\"\"\"\n",
    "        df = pd.read_csv(csv_path)\n",
    "\n",
    "        # Filtra apenas as linhas com respostas v√°lidas\n",
    "        valid_rows = df[\n",
    "            (df['answer'].notna()) &\n",
    "            (df['answer'] != '')\n",
    "        ]\n",
    "\n",
    "        for idx, row in valid_rows.iterrows():\n",
    "            key = f\"item_{idx}\"\n",
    "            self.original_content[key] = {\n",
    "                'answer': row['answer']\n",
    "            }\n",
    "\n",
    "    def load_generated_content(self, generated_text: str):\n",
    "        \"\"\"Carrega o conte√∫do gerado\"\"\"\n",
    "        self.generated_content = generated_text\n",
    "\n",
    "    def normalize_text(self, text: str) -> str:\n",
    "        \"\"\"Normaliza texto para compara√ß√£o mais flex√≠vel\"\"\"\n",
    "        # Remove acentos b√°sicos\n",
    "        replacements = {\n",
    "            '√°': 'a', '√†': 'a', '√£': 'a', '√¢': 'a', '√§': 'a',\n",
    "            '√©': 'e', '√®': 'e', '√™': 'e', '√´': 'e',\n",
    "            '√≠': 'i', '√¨': 'i', '√Æ': 'i', '√Ø': 'i',\n",
    "            '√≥': 'o', '√≤': 'o', '√µ': 'o', '√¥': 'o', '√∂': 'o',\n",
    "            '√∫': 'u', '√π': 'u', '√ª': 'u', '√º': 'u',\n",
    "            '√ß': 'c', '√±': 'n'\n",
    "        }\n",
    "\n",
    "        text = text.lower()\n",
    "        for old, new in replacements.items():\n",
    "            text = text.replace(old, new)\n",
    "\n",
    "        # Remove pontua√ß√£o e normaliza espa√ßos\n",
    "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        return text.strip()\n",
    "\n",
    "    def extract_key_concepts(self, text: str) -> List[str]:\n",
    "        \"\"\"Extrai conceitos-chave do texto (palavras e frases importantes)\"\"\"\n",
    "        normalized = self.normalize_text(text)\n",
    "\n",
    "        # Palavras importantes (substantivos, verbos, adjetivos)\n",
    "        words = normalized.split()\n",
    "\n",
    "        # Filtrar palavras muito comuns\n",
    "        stopwords = {\n",
    "            'a', 'e', 'o', 'de', 'da', 'do', 'em', 'para', 'com', 'por', 'que', 'se', 'na', 'no',\n",
    "            'um', 'uma', 'os', 'as', 'dos', 'das', 'nos', 'nas', 'ao', 'aos', 'pela', 'pelo',\n",
    "            'mas', 'ou', 'quando', 'onde', 'como', 'muito', 'mais', 'menos', 'ate', 'seu', 'sua',\n",
    "            'seus', 'suas', 'meu', 'minha', 'meus', 'minhas', 'era', 'foi', 'ser', 'ter', 'estar',\n",
    "            'foi', 'tinha', 'tem', 'tinha', 'eram', 'sendo', 'sido', 'ja', 'sempre', 'nunca',\n",
    "            'tambem', 'ainda', 'depois', 'antes', 'entao', 'isso', 'essa', 'este', 'esta',\n",
    "            'aquele', 'aquela', 'dele', 'dela', 'deles', 'delas', 'me', 'te', 'lhe', 'nos', 'vos'\n",
    "        }\n",
    "\n",
    "        # Palavras importantes (pelo menos 3 caracteres e n√£o stopwords)\n",
    "        key_words = [word for word in words if len(word) >= 3 and word not in stopwords]\n",
    "\n",
    "        # Frases importantes (sequ√™ncias de 2-4 palavras)\n",
    "        key_phrases = []\n",
    "        for i in range(len(key_words) - 1):\n",
    "            phrase = ' '.join(key_words[i:i+2])\n",
    "            if len(phrase) > 8:  # Frases com mais de 8 caracteres\n",
    "                key_phrases.append(phrase)\n",
    "\n",
    "        # Combinar palavras e frases\n",
    "        return key_words + key_phrases\n",
    "\n",
    "    def calculate_similarity(self, text1: str, text2: str) -> float:\n",
    "        \"\"\"Calcula similaridade entre dois textos usando diferentes m√©tricas\"\"\"\n",
    "        norm1 = self.normalize_text(text1)\n",
    "        norm2 = self.normalize_text(text2)\n",
    "\n",
    "        # Similaridade b√°sica usando SequenceMatcher\n",
    "        basic_similarity = SequenceMatcher(None, norm1, norm2).ratio()\n",
    "\n",
    "        # Similaridade baseada em conceitos-chave\n",
    "        concepts1 = set(self.extract_key_concepts(text1))\n",
    "        concepts2 = set(self.extract_key_concepts(text2))\n",
    "\n",
    "        if not concepts1 or not concepts2:\n",
    "            concept_similarity = 0.0\n",
    "        else:\n",
    "            intersection = len(concepts1 & concepts2)\n",
    "            union = len(concepts1 | concepts2)\n",
    "            concept_similarity = intersection / union if union > 0 else 0.0\n",
    "\n",
    "        # Peso maior para similaridade de conceitos\n",
    "        final_similarity = (basic_similarity * 0.3) + (concept_similarity * 0.7)\n",
    "\n",
    "        return final_similarity\n",
    "\n",
    "    def check_content_presence(self, original_answer: str, generated_text: str) -> Dict:\n",
    "        \"\"\"Verifica se o conte√∫do original est√° presente no texto gerado\"\"\"\n",
    "        # Extrai conceitos-chave do texto original\n",
    "        original_concepts = self.extract_key_concepts(original_answer)\n",
    "\n",
    "        # Normaliza o texto gerado\n",
    "        normalized_generated = self.normalize_text(generated_text)\n",
    "\n",
    "        # Verifica quantos conceitos est√£o presentes\n",
    "        present_concepts = []\n",
    "        missing_concepts = []\n",
    "\n",
    "        for concept in original_concepts:\n",
    "            if concept in normalized_generated:\n",
    "                present_concepts.append(concept)\n",
    "            else:\n",
    "                # Verifica similaridade parcial\n",
    "                found_similar = False\n",
    "                for word in normalized_generated.split():\n",
    "                    if self.calculate_similarity(concept, word) > 0.8:\n",
    "                        present_concepts.append(concept)\n",
    "                        found_similar = True\n",
    "                        break\n",
    "\n",
    "                if not found_similar:\n",
    "                    missing_concepts.append(concept)\n",
    "\n",
    "        total_concepts = len(original_concepts)\n",
    "        present_count = len(present_concepts)\n",
    "\n",
    "        coverage_percent = (present_count / total_concepts) * 100 if total_concepts > 0 else 0\n",
    "\n",
    "        return {\n",
    "            'total_concepts': total_concepts,\n",
    "            'present_concepts': present_count,\n",
    "            'coverage_percent': coverage_percent,\n",
    "            'missing_concepts': missing_concepts[:5],  # Apenas os primeiros 5\n",
    "            'similarity_score': self.calculate_similarity(original_answer, generated_text) * 100\n",
    "        }\n",
    "\n",
    "    def compare_character_count(self) -> Dict:\n",
    "        \"\"\"Compara a quantidade de caracteres entre original e gerado\"\"\"\n",
    "        # Contar caracteres do conte√∫do original\n",
    "        original_chars = sum(len(item['answer']) for item in self.original_content.values())\n",
    "        generated_chars = len(self.generated_content)\n",
    "\n",
    "        # Calcular diferen√ßa percentual\n",
    "        if original_chars > 0:\n",
    "            expansion_ratio = generated_chars / original_chars\n",
    "            difference_percent = ((generated_chars - original_chars) / original_chars) * 100\n",
    "        else:\n",
    "            expansion_ratio = 0\n",
    "            difference_percent = 0\n",
    "\n",
    "        return {\n",
    "            'original_chars': original_chars,\n",
    "            'generated_chars': generated_chars,\n",
    "            'expansion_ratio': expansion_ratio,\n",
    "            'difference_percent': difference_percent,\n",
    "            'status': self._get_expansion_status(expansion_ratio)\n",
    "        }\n",
    "\n",
    "    def _get_expansion_status(self, ratio: float) -> str:\n",
    "        \"\"\"Determina o status baseado na raz√£o de expans√£o\"\"\"\n",
    "        if ratio < 0.5:\n",
    "            return \"‚ùå MUITO COMPRIMIDO\"\n",
    "        elif ratio < 0.8:\n",
    "            return \"‚ö†Ô∏è COMPRIMIDO\"\n",
    "        elif ratio < 1.2:\n",
    "            return \"‚úÖ SIMILAR\"\n",
    "        elif ratio < 2.0:\n",
    "            return \"‚úÖ EXPANDIDO\"\n",
    "        elif ratio < 3.0:\n",
    "            return \"‚ö†Ô∏è MUITO EXPANDIDO\"\n",
    "        else:\n",
    "            return \"‚ùå EXTREMAMENTE EXPANDIDO\"\n",
    "\n",
    "    def check_content_coverage(self) -> Dict:\n",
    "        \"\"\"Verifica cobertura do conte√∫do com l√≥gica melhorada\"\"\"\n",
    "        coverage_report = {\n",
    "            'total_original_items': len(self.original_content),\n",
    "            'covered_items': 0,\n",
    "            'missing_items': [],\n",
    "            'coverage_percentage': 0,\n",
    "            'details': [],\n",
    "            'character_analysis': self.compare_character_count()\n",
    "        }\n",
    "\n",
    "        for key, item in self.original_content.items():\n",
    "            presence_analysis = self.check_content_presence(item['answer'], self.generated_content)\n",
    "\n",
    "            item_report = {\n",
    "                'key': key,\n",
    "                'answer': item['answer'],\n",
    "                'coverage_percent': presence_analysis['coverage_percent'],\n",
    "                'similarity_score': presence_analysis['similarity_score'],\n",
    "                'present_concepts': presence_analysis['present_concepts'],\n",
    "                'total_concepts': presence_analysis['total_concepts'],\n",
    "                'missing_concepts': presence_analysis['missing_concepts']\n",
    "            }\n",
    "\n",
    "            coverage_report['details'].append(item_report)\n",
    "\n",
    "            # Considera coberto se tem boa cobertura de conceitos OU alta similaridade\n",
    "            if presence_analysis['coverage_percent'] > 40 or presence_analysis['similarity_score'] > 30:\n",
    "                coverage_report['covered_items'] += 1\n",
    "            else:\n",
    "                coverage_report['missing_items'].append(item_report)\n",
    "\n",
    "        coverage_report['coverage_percentage'] = (\n",
    "            coverage_report['covered_items'] / coverage_report['total_original_items']\n",
    "        ) * 100\n",
    "\n",
    "        return coverage_report\n",
    "\n",
    "    def generate_diff_report(self) -> str:\n",
    "        \"\"\"Gera relat√≥rio melhorado no estilo diff do GitHub\"\"\"\n",
    "        coverage = self.check_content_coverage()\n",
    "        char_analysis = coverage['character_analysis']\n",
    "\n",
    "        report = []\n",
    "        report.append(\"# üìä RELAT√ìRIO DE VALIDA√á√ÉO DE CONTE√öDO - VERS√ÉO MELHORADA\")\n",
    "        report.append(\"=\" * 70)\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Resumo geral\n",
    "        report.append(\"## üìà RESUMO GERAL\")\n",
    "        report.append(f\"- **Total de itens originais:** {coverage['total_original_items']}\")\n",
    "        report.append(f\"- **Itens cobertos:** {coverage['covered_items']}\")\n",
    "        report.append(f\"- **Cobertura geral:** {coverage['coverage_percentage']:.1f}%\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # An√°lise de caracteres\n",
    "        report.append(\"## üìè AN√ÅLISE DE CARACTERES\")\n",
    "        report.append(f\"- **Caracteres originais:** {char_analysis['original_chars']:,}\")\n",
    "        report.append(f\"- **Caracteres gerados:** {char_analysis['generated_chars']:,}\")\n",
    "        report.append(f\"- **Raz√£o de expans√£o:** {char_analysis['expansion_ratio']:.2f}x\")\n",
    "        report.append(f\"- **Diferen√ßa percentual:** {char_analysis['difference_percent']:+.1f}%\")\n",
    "        report.append(f\"- **Status:** {char_analysis['status']}\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Status da cobertura\n",
    "        if coverage['coverage_percentage'] >= 80:\n",
    "            status = \"‚úÖ EXCELENTE\"\n",
    "        elif coverage['coverage_percentage'] >= 60:\n",
    "            status = \"‚úÖ BOM\"\n",
    "        elif coverage['coverage_percentage'] >= 40:\n",
    "            status = \"‚ö†Ô∏è REGULAR\"\n",
    "        else:\n",
    "            status = \"‚ùå INSUFICIENTE\"\n",
    "\n",
    "        report.append(f\"**Status Geral:** {status}\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        # Itens bem cobertos\n",
    "        well_covered = [item for item in coverage['details'] if item['coverage_percent'] >= 60 or item['similarity_score'] >= 40]\n",
    "        if well_covered:\n",
    "            report.append(\"## ‚úÖ CONTE√öDO BEM COBERTO\")\n",
    "            report.append(\"\")\n",
    "            for item in well_covered:\n",
    "                report.append(f\"### + {item['key']}\")\n",
    "                report.append(f\"**Cobertura de conceitos:** {item['coverage_percent']:.1f}% ({item['present_concepts']}/{item['total_concepts']})\")\n",
    "                report.append(f\"**Similaridade:** {item['similarity_score']:.1f}%\")\n",
    "                report.append(\"```diff\")\n",
    "                report.append(f\"+ ‚úÖ Conte√∫do bem integrado no cap√≠tulo\")\n",
    "                report.append(\"```\")\n",
    "                report.append(\"\")\n",
    "\n",
    "        # Itens com cobertura parcial\n",
    "        partial_covered = [item for item in coverage['details']\n",
    "                          if (20 <= item['coverage_percent'] < 60) and item['similarity_score'] < 40]\n",
    "        if partial_covered:\n",
    "            report.append(\"## ‚ö†Ô∏è CONTE√öDO PARCIALMENTE COBERTO\")\n",
    "            report.append(\"\")\n",
    "            for item in partial_covered:\n",
    "                report.append(f\"### ~ {item['key']}\")\n",
    "                report.append(f\"**Cobertura de conceitos:** {item['coverage_percent']:.1f}% ({item['present_concepts']}/{item['total_concepts']})\")\n",
    "                report.append(f\"**Similaridade:** {item['similarity_score']:.1f}%\")\n",
    "                report.append(\"```diff\")\n",
    "                report.append(f\"~ ‚ö†Ô∏è Parte do conte√∫do pode estar ausente ou muito reformulado\")\n",
    "                if item['missing_concepts']:\n",
    "                    report.append(\"- Conceitos possivelmente ausentes:\")\n",
    "                    for concept in item['missing_concepts']:\n",
    "                        report.append(f\"- {concept}\")\n",
    "                report.append(\"```\")\n",
    "                report.append(\"\")\n",
    "\n",
    "        # Itens com baixa cobertura\n",
    "        low_covered = [item for item in coverage['details']\n",
    "                      if item['coverage_percent'] < 20 and item['similarity_score'] < 30]\n",
    "        if low_covered:\n",
    "            report.append(\"## ‚ùå CONTE√öDO COM BAIXA COBERTURA\")\n",
    "            report.append(\"\")\n",
    "            for item in low_covered:\n",
    "                report.append(f\"### - {item['key']}\")\n",
    "                report.append(f\"**Cobertura de conceitos:** {item['coverage_percent']:.1f}% ({item['present_concepts']}/{item['total_concepts']})\")\n",
    "                report.append(f\"**Similaridade:** {item['similarity_score']:.1f}%\")\n",
    "                report.append(\"```diff\")\n",
    "                report.append(f\"- ‚ùå Conte√∫do significativamente ausente\")\n",
    "                report.append(\"- Resposta original:\")\n",
    "                answer_preview = item['answer'][:300] + \"...\" if len(item['answer']) > 300 else item['answer']\n",
    "                report.append(f\"- {answer_preview}\")\n",
    "                report.append(\"```\")\n",
    "                report.append(\"\")\n",
    "\n",
    "        # Recomenda√ß√µes\n",
    "        report.append(\"## üîç RECOMENDA√á√ïES\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        if coverage['coverage_percentage'] < 60:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"- ‚ö†Ô∏è ATEN√á√ÉO: Cobertura abaixo do ideal\")\n",
    "            report.append(\"+ Revisar itens com baixa cobertura\")\n",
    "            report.append(\"+ Verificar se informa√ß√µes importantes foram omitidas\")\n",
    "            report.append(\"+ Considerar incluir mais detalhes dos itens ausentes\")\n",
    "            report.append(\"```\")\n",
    "        else:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"+ ‚úÖ Cobertura satisfat√≥ria\")\n",
    "            report.append(\"+ Conte√∫do bem integrado e reformulado\")\n",
    "            report.append(\"+ Cap√≠tulo pronto para revis√£o final\")\n",
    "            report.append(\"```\")\n",
    "\n",
    "        # An√°lise da expans√£o\n",
    "        report.append(\"\")\n",
    "        report.append(\"## üìä AN√ÅLISE DE EXPANS√ÉO\")\n",
    "        report.append(\"\")\n",
    "\n",
    "        if char_analysis['expansion_ratio'] < 0.8:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"- ‚ö†Ô∏è Conte√∫do pode estar muito comprimido\")\n",
    "            report.append(\"+ Considerar adicionar mais detalhes e contexto\")\n",
    "            report.append(\"```\")\n",
    "        elif char_analysis['expansion_ratio'] > 2.5:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"- ‚ö†Ô∏è Conte√∫do pode estar muito expandido\")\n",
    "            report.append(\"+ Verificar se h√° informa√ß√µes desnecess√°rias\")\n",
    "            report.append(\"```\")\n",
    "        else:\n",
    "            report.append(\"```diff\")\n",
    "            report.append(\"+ ‚úÖ Expans√£o adequada para um cap√≠tulo narrativo\")\n",
    "            report.append(\"```\")\n",
    "\n",
    "        report.append(\"\")\n",
    "        report.append(\"---\")\n",
    "        report.append(\"*Relat√≥rio gerado automaticamente pelo ContentValidator v2.0*\")\n",
    "        report.append(\"*L√≥gica melhorada para an√°lise de conte√∫do reformulado*\")\n",
    "\n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "    def run_validation(self, csv_path: str, generated_text: str) -> str:\n",
    "        \"\"\"Executa valida√ß√£o completa\"\"\"\n",
    "        print(\"üîÑ Carregando dados originais...\")\n",
    "        self.load_original_data(csv_path)\n",
    "\n",
    "        print(\"üîÑ Carregando conte√∫do gerado...\")\n",
    "        self.load_generated_content(generated_text)\n",
    "\n",
    "        print(\"üîÑ Analisando cobertura com l√≥gica melhorada...\")\n",
    "\n",
    "        print(\"üîÑ Gerando relat√≥rio...\")\n",
    "        report = self.generate_diff_report()\n",
    "\n",
    "        return report\n",
    "\n",
    "# 3. PREPARAR DADOS DE EXEMPLO\n",
    "csv_data = \"/caminho_para_csv_com_answers\"\n",
    "\n",
    "# 4. DEFINIR CONTE√öDO GERADO (cole seu cap√≠tulo aqui)\n",
    "generated_text = \"\"\"\n",
    "*CONTE√öDO GERADO*\n",
    "\"\"\"\n",
    "\n",
    "# 5. EXECUTAR VALIDA√á√ÉO\n",
    "validator = ContentValidator()\n",
    "\n",
    "# Executar valida√ß√£o\n",
    "print(\"üöÄ Iniciando valida√ß√£o com l√≥gica melhorada...\")\n",
    "report = validator.run_validation(csv_data, generated_text)\n",
    "\n",
    "# 6. EXIBIR RESULTADO\n",
    "display(Markdown(report))\n",
    "\n",
    "# 7. FUN√á√ÉO PARA AN√ÅLISE DETALHADA\n",
    "def detailed_analysis(validator):\n",
    "    \"\"\"An√°lise detalhada item por item\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"AN√ÅLISE DETALHADA ITEM POR ITEM\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    coverage = validator.check_content_coverage()\n",
    "\n",
    "    for i, item in enumerate(coverage['details'], 1):\n",
    "        print(f\"\\n{i}. {item['key']}\")\n",
    "        print(f\"   Cobertura de conceitos: {item['coverage_percent']:.1f}%\")\n",
    "        print(f\"   Similaridade geral: {item['similarity_score']:.1f}%\")\n",
    "        print(f\"   Conceitos presentes: {item['present_concepts']}/{item['total_concepts']}\")\n",
    "\n",
    "        if item['coverage_percent'] >= 60 or item['similarity_score'] >= 40:\n",
    "            print(\"   Status: ‚úÖ BEM COBERTO\")\n",
    "        elif item['coverage_percent'] >= 20 or item['similarity_score'] >= 20:\n",
    "            print(\"   Status: ‚ö†Ô∏è PARCIALMENTE COBERTO\")\n",
    "        else:\n",
    "            print(\"   Status: ‚ùå BAIXA COBERTURA\")\n",
    "\n",
    "        if item['missing_concepts']:\n",
    "            print(\"   Conceitos ausentes:\")\n",
    "            for concept in item['missing_concepts']:\n",
    "                print(f\"   - {concept}\")\n",
    "\n",
    "# Executar an√°lise detalhada\n",
    "detailed_analysis(validator)\n",
    "\n",
    "# 8. FUN√á√ÉO PARA RELAT√ìRIO DE CONCEITOS\n",
    "def concept_analysis_report(validator):\n",
    "    \"\"\"Relat√≥rio focado em conceitos-chave\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RELAT√ìRIO DE CONCEITOS-CHAVE\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    for key, item in validator.original_content.items():\n",
    "        print(f\"\\nüìù {key}:\")\n",
    "        print(f\"Texto original: {item['answer'][:200]}...\")\n",
    "\n",
    "        concepts = validator.extract_key_concepts(item['answer'])\n",
    "        print(f\"Conceitos extra√≠dos: {concepts[:10]}\")  # Primeiros 10\n",
    "\n",
    "        presence = validator.check_content_presence(item['answer'], validator.generated_content)\n",
    "        print(f\"Cobertura: {presence['coverage_percent']:.1f}%\")\n",
    "        print(f\"Similaridade: {presence['similarity_score']:.1f}%\")\n",
    "\n",
    "# Executar an√°lise de conceitos\n",
    "concept_analysis_report(validator)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
